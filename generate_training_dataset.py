#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
generate_training_dataset.py
å°†å¯¹é½ç»“æœè½¬æ¢ä¸ºè®­ç»ƒæ‰€éœ€çš„CSVæ ¼å¼

è¾“å…¥ï¼š
  - manifest_out_plus/windows_aligned.csv  ï¼ˆçª—å£é…å¯¹ï¼‰
  - manifest_out_plus/results.csv          ï¼ˆæ ·æœ¬è´¨é‡ï¼‰
  - åŸå§‹æ ‡ç­¾æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰

è¾“å‡ºï¼š
  - data/train.csv  ï¼ˆ70% æœ‰æ ‡ç­¾ï¼‰
  - data/val.csv    ï¼ˆ30% æœ‰æ ‡ç­¾ï¼‰
  - data/unlabeled.csv ï¼ˆæ— æ ‡ç­¾æ ·æœ¬ï¼Œç”¨äºåŠç›‘ç£ï¼‰

å­—æ®µï¼š
  video_path, audio_path, label, is_labeled, 
  video_start_frame, video_end_frame, audio_start_s, audio_end_s,
  sample_quality, confidence_score
"""

import argparse
import csv
from pathlib import Path
from typing import Dict, List, Tuple
import pandas as pd
import numpy as np
from collections import defaultdict


class DatasetGenerator:
    """æ•°æ®é›†ç”Ÿæˆå™¨"""
    
    def __init__(self, 
                 aligned_csv: str,
                 results_csv: str,
                 labels_csv: str = None,
                 quality_threshold: float = 0.7,
                 min_score: float = 0.6,
                 train_ratio: float = 0.7):
        """
        Args:
            aligned_csv: windows_aligned.csvè·¯å¾„
            results_csv: results.csvè·¯å¾„  
            labels_csv: åŸå§‹æ ‡ç­¾æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œæ ¼å¼: sample,labelï¼‰
            quality_threshold: æ ·æœ¬è´¨é‡é˜ˆå€¼ï¼ˆç”¨äºå†³å®šis_labeledï¼‰
            min_score: æœ€å°é…å¯¹åˆ†æ•°ï¼ˆè¿‡æ»¤ä½è´¨é‡çª—å£ï¼‰
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        """
        self.aligned_csv = Path(aligned_csv)
        self.results_csv = Path(results_csv)
        self.labels_csv = Path(labels_csv) if labels_csv else None
        
        self.quality_threshold = quality_threshold
        self.min_score = min_score
        self.train_ratio = train_ratio
        
        # åŠ è½½æ•°æ®
        self.aligned_df = pd.read_csv(aligned_csv)
        self.results_df = pd.read_csv(results_csv)
        
        # åŠ è½½æ ‡ç­¾ï¼ˆå¦‚æœæœ‰ï¼‰
        self.labels = {}
        if self.labels_csv and self.labels_csv.exists():
            labels_df = pd.read_csv(self.labels_csv)
            self.labels = dict(zip(labels_df['sample'], labels_df['label']))
            print(f"âœ… åŠ è½½äº† {len(self.labels)} ä¸ªæ ‡ç­¾")
        else:
            print("âš ï¸  æœªæä¾›æ ‡ç­¾æ–‡ä»¶ï¼Œå°†æ ¹æ®æ–‡ä»¶åæ¨æ–­æ ‡ç­¾")
    
    def _infer_label_from_path(self, sample_name: str) -> int:
        """
        ä»æ ·æœ¬åæ¨æ–­æ ‡ç­¾ï¼ˆæ ¹æ®Intelç„Šæ¥æ•°æ®é›†å‘½åè§„åˆ™ï¼‰
        
        Intelæ•°æ®é›†è§„åˆ™ï¼š
        - normal_xxx.mp4 -> 0 (æ­£å¸¸)
        - defect_xxx.mp4 -> 1 (ç¼ºé™·)
        - anomaly_xxx.mp4 -> 1 (å¼‚å¸¸)
        """
        name_lower = sample_name.lower()
        
        if 'normal' in name_lower or 'good' in name_lower:
            return 0
        elif 'defect' in name_lower or 'anomaly' in name_lower or 'bad' in name_lower:
            return 1
        else:
            # é»˜è®¤è¿”å›-1è¡¨ç¤ºæœªçŸ¥ï¼ˆä½œä¸ºæ— æ ‡ç­¾æ ·æœ¬ï¼‰
            return -1
    
    def _compute_sample_quality(self, sample_stats: Dict) -> float:
        """
        è®¡ç®—æ ·æœ¬ç»¼åˆè´¨é‡åˆ†æ•° [0-1]
        
        è€ƒè™‘å› ç´ ï¼š
        - pair_pass_rate: é…å¯¹é€šè¿‡ç‡ï¼ˆæƒé‡0.4ï¼‰
        - corr_med: éŸ³è§†é¢‘ç›¸å…³æ€§ï¼ˆæƒé‡0.3ï¼‰
        - 1 - center_dev_med: ä¸­å¿ƒå¯¹é½åº¦ï¼ˆæƒé‡0.2ï¼‰
        - 1 - (resid_med_ms/100): æ˜ å°„æ®‹å·®ï¼ˆæƒé‡0.1ï¼‰
        """
        try:
            # å½’ä¸€åŒ–å„æŒ‡æ ‡
            pair_rate = float(sample_stats.get('pair_pass_rate', 0.0))
            corr = max(0.0, float(sample_stats.get('corr_med', 0.0)))  # ç›¸å…³æ€§å¯èƒ½ä¸ºè´Ÿ
            
            # ä¸­å¿ƒåå·®ï¼šè¶Šå°è¶Šå¥½ï¼Œå‡è®¾>1så°±æ˜¯å¾ˆå·®
            dev = float(sample_stats.get('center_dev_med', 1.0))
            dev_score = max(0.0, 1.0 - dev)
            
            # æ˜ å°„æ®‹å·®ï¼šå‡è®¾>100mså°±æ˜¯å¾ˆå·®
            resid = float(sample_stats.get('resid_med_ms', 100.0))
            resid_score = max(0.0, 1.0 - resid / 100.0)
            
            # åŠ æƒå¹³å‡
            quality = (
                0.4 * pair_rate +
                0.3 * corr +
                0.2 * dev_score +
                0.1 * resid_score
            )
            
            return float(np.clip(quality, 0.0, 1.0))
            
        except Exception as e:
            print(f"âš ï¸  è´¨é‡è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def generate_dataset(self, output_dir: str = "data"):
        """ç”Ÿæˆè®­ç»ƒ/éªŒè¯/æ— æ ‡ç­¾æ•°æ®é›†"""
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        print("\n" + "="*70)
        print("ğŸš€ å¼€å§‹ç”Ÿæˆè®­ç»ƒæ•°æ®é›†")
        print("="*70)
        
        # 1. æŒ‰æ ·æœ¬åˆ†ç»„çª—å£å¯¹
        sample_windows = defaultdict(list)
        
        for _, row in self.aligned_df.iterrows():
            sample = row['sample']
            
            # è¿‡æ»¤ä½è´¨é‡çª—å£
            score = float(row.get('score', 0.0))
            keep = int(row.get('keep', 0))
            
            if score < self.min_score or not keep:
                continue
            
            sample_windows[sample].append(row)
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  - æ€»æ ·æœ¬æ•°: {len(sample_windows)}")
        print(f"  - æ€»çª—å£å¯¹æ•°: {sum(len(wins) for wins in sample_windows.values())}")
        
        # 2. ä¸ºæ¯ä¸ªæ ·æœ¬è·å–è´¨é‡ç»Ÿè®¡å’Œæ ‡ç­¾
        samples_data = []
        
        for sample, windows in sample_windows.items():
            # è·å–æ ·æœ¬è´¨é‡ç»Ÿè®¡
            sample_stats = self.results_df[self.results_df['sample'] == sample]
            
            if sample_stats.empty:
                print(f"âš ï¸  æ ·æœ¬ {sample} æ— è´¨é‡ç»Ÿè®¡ï¼Œè·³è¿‡")
                continue
            
            stats_dict = sample_stats.iloc[0].to_dict()
            
            # è®¡ç®—ç»¼åˆè´¨é‡
            quality = self._compute_sample_quality(stats_dict)
            
            # è·å–æ ‡ç­¾
            if sample in self.labels:
                label = self.labels[sample]
            else:
                label = self._infer_label_from_path(sample)
            
            # å†³å®šæ˜¯å¦ä½œä¸ºæœ‰æ ‡ç­¾æ ·æœ¬
            # é«˜è´¨é‡æ ·æœ¬ -> æœ‰æ ‡ç­¾
            # ä½è´¨é‡æ ·æœ¬ -> æ— æ ‡ç­¾ï¼ˆç”¨äºåŠç›‘ç£ï¼‰
            is_labeled = (quality >= self.quality_threshold) and (label != -1)
            
            # è·å–è·¯å¾„
            video_path = stats_dict.get('video', '')
            audio_path = stats_dict.get('audio', '')
            
            # ä¸ºæ¯ä¸ªçª—å£å¯¹åˆ›å»ºä¸€æ¡è®°å½•
            for win_row in windows:
                record = {
                    'sample': sample,
                    'video_path': video_path,
                    'audio_path': audio_path,
                    'label': int(label),
                    'is_labeled': int(is_labeled),
                    
                    # çª—å£ä¿¡æ¯ï¼ˆå…³é”®ï¼ï¼‰
                    'video_start_frame': int(win_row['v_start_frame']),
                    'video_end_frame': int(win_row['v_end_frame']),
                    'audio_start_s': float(win_row['a_start_s']),
                    'audio_end_s': float(win_row['a_end_s']),
                    
                    # è´¨é‡æŒ‡æ ‡
                    'sample_quality': round(quality, 4),
                    'window_score': float(win_row['score']),
                    
                    # é¢å¤–å…ƒæ•°æ®
                    'pair_strategy': win_row.get('strategy', ''),
                    'temporal_iou': float(win_row.get('temporal_iou', 0.0))
                }
                
                samples_data.append(record)
        
        # è½¬ä¸ºDataFrame
        df = pd.DataFrame(samples_data)
        
        print(f"\nğŸ“ˆ ç”Ÿæˆçš„æ ·æœ¬ç»Ÿè®¡:")
        print(f"  - æ€»è®°å½•æ•°: {len(df)}")
        print(f"  - æœ‰æ ‡ç­¾: {df['is_labeled'].sum()} ({df['is_labeled'].mean()*100:.1f}%)")
        print(f"  - æ— æ ‡ç­¾: {(~df['is_labeled'].astype(bool)).sum()}")
        
        if len(df[df['is_labeled'] == 1]) > 0:
            print(f"\n  æ ‡ç­¾åˆ†å¸ƒï¼ˆæœ‰æ ‡ç­¾æ ·æœ¬ï¼‰:")
            label_counts = df[df['is_labeled'] == 1]['label'].value_counts()
            for label, count in label_counts.items():
                label_name = "æ­£å¸¸" if label == 0 else "ç¼ºé™·" if label == 1 else "æœªçŸ¥"
                print(f"    - {label_name} (label={label}): {count}")
        
        # 3. åˆ†å‰²æ•°æ®é›†
        # åªåœ¨æœ‰æ ‡ç­¾æ•°æ®ä¸Šåštrain/valåˆ’åˆ†
        labeled_df = df[df['is_labeled'] == 1].copy()
        unlabeled_df = df[df['is_labeled'] == 0].copy()
        
        if len(labeled_df) == 0:
            print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æœ‰æ ‡ç­¾æ ·æœ¬ï¼è¯·æ£€æŸ¥quality_thresholdè®¾ç½®")
            return
        
        # æŒ‰æ ·æœ¬ååˆ’åˆ†ï¼ˆç¡®ä¿åŒä¸€æ ·æœ¬çš„æ‰€æœ‰çª—å£åœ¨åŒä¸€é›†åˆï¼‰
        unique_samples = labeled_df['sample'].unique()
        np.random.shuffle(unique_samples)
        
        n_train = int(len(unique_samples) * self.train_ratio)
        train_samples = unique_samples[:n_train]
        val_samples = unique_samples[n_train:]
        
        train_df = labeled_df[labeled_df['sample'].isin(train_samples)]
        val_df = labeled_df[labeled_df['sample'].isin(val_samples)]
        
        print(f"\nğŸ“‚ æ•°æ®é›†åˆ’åˆ†:")
        print(f"  - è®­ç»ƒé›†: {len(train_df)} çª—å£å¯¹ ({len(train_samples)} æ ·æœ¬)")
        print(f"  - éªŒè¯é›†: {len(val_df)} çª—å£å¯¹ ({len(val_samples)} æ ·æœ¬)")
        print(f"  - æ— æ ‡ç­¾: {len(unlabeled_df)} çª—å£å¯¹")
        
        # 4. ä¿å­˜CSV
        train_csv = output_dir / "train.csv"
        val_csv = output_dir / "val.csv"
        unlabeled_csv = output_dir / "unlabeled.csv"
        full_csv = output_dir / "full_dataset.csv"
        
        train_df.to_csv(train_csv, index=False)
        val_df.to_csv(val_csv, index=False)
        unlabeled_df.to_csv(unlabeled_csv, index=False)
        df.to_csv(full_csv, index=False)
        
        print(f"\nâœ… æ•°æ®é›†å·²ä¿å­˜:")
        print(f"  - {train_csv}")
        print(f"  - {val_csv}")
        print(f"  - {unlabeled_csv}")
        print(f"  - {full_csv}")
        
        # 5. ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š
        self._generate_report(train_df, val_df, unlabeled_df, output_dir)
        
        return train_df, val_df, unlabeled_df
    
    def _generate_report(self, train_df, val_df, unlabeled_df, output_dir):
        """ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š"""
        report_path = output_dir / "dataset_report.txt"
        
        with open(report_path, 'w') as f:
            f.write("="*70 + "\n")
            f.write("æ•°æ®é›†ç”ŸæˆæŠ¥å‘Š\n")
            f.write("="*70 + "\n\n")
            
            # åŸºæœ¬ç»Ÿè®¡
            f.write("ã€åŸºæœ¬ç»Ÿè®¡ã€‘\n")
            f.write(f"è®­ç»ƒé›†: {len(train_df)} çª—å£å¯¹\n")
            f.write(f"éªŒè¯é›†: {len(val_df)} çª—å£å¯¹\n")
            f.write(f"æ— æ ‡ç­¾: {len(unlabeled_df)} çª—å£å¯¹\n\n")
            
            # è´¨é‡åˆ†å¸ƒ
            f.write("ã€è´¨é‡åˆ†å¸ƒã€‘\n")
            for name, df in [("è®­ç»ƒé›†", train_df), ("éªŒè¯é›†", val_df)]:
                if len(df) > 0:
                    f.write(f"\n{name}:\n")
                    f.write(f"  å¹³å‡è´¨é‡: {df['sample_quality'].mean():.3f}\n")
                    f.write(f"  è´¨é‡ä¸­ä½æ•°: {df['sample_quality'].median():.3f}\n")
                    f.write(f"  è´¨é‡èŒƒå›´: [{df['sample_quality'].min():.3f}, {df['sample_quality'].max():.3f}]\n")
            
            # æ ‡ç­¾åˆ†å¸ƒ
            f.write("\nã€æ ‡ç­¾åˆ†å¸ƒã€‘\n")
            for name, df in [("è®­ç»ƒé›†", train_df), ("éªŒè¯é›†", val_df)]:
                if len(df) > 0:
                    f.write(f"\n{name}:\n")
                    for label, count in df['label'].value_counts().items():
                        label_name = "æ­£å¸¸" if label == 0 else "ç¼ºé™·"
                        ratio = count / len(df) * 100
                        f.write(f"  {label_name}: {count} ({ratio:.1f}%)\n")
            
            # çª—å£åˆ†æ•°åˆ†å¸ƒ
            f.write("\nã€çª—å£é…å¯¹è´¨é‡ã€‘\n")
            for name, df in [("è®­ç»ƒé›†", train_df), ("éªŒè¯é›†", val_df)]:
                if len(df) > 0:
                    f.write(f"\n{name}:\n")
                    f.write(f"  å¹³å‡åˆ†æ•°: {df['window_score'].mean():.3f}\n")
                    f.write(f"  åˆ†æ•°>0.8: {(df['window_score'] > 0.8).sum()} ({(df['window_score'] > 0.8).mean()*100:.1f}%)\n")
        
        print(f"  - {report_path}")


def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆè®­ç»ƒæ•°æ®é›†")
    
    # è¾“å…¥æ–‡ä»¶
    parser.add_argument("--aligned_csv", required=True,
                        help="windows_aligned.csvè·¯å¾„")
    parser.add_argument("--results_csv", required=True,
                        help="results.csvè·¯å¾„")
    parser.add_argument("--labels_csv", default=None,
                        help="æ ‡ç­¾æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œæ ¼å¼: sample,labelï¼‰")
    
    # è¾“å‡ºç›®å½•
    parser.add_argument("--output_dir", default="data",
                        help="è¾“å‡ºç›®å½•")
    
    # å‚æ•°
    parser.add_argument("--quality_threshold", type=float, default=0.7,
                        help="æ ·æœ¬è´¨é‡é˜ˆå€¼ï¼ˆé«˜äºæ­¤å€¼æ‰ä½œä¸ºæœ‰æ ‡ç­¾æ ·æœ¬ï¼‰")
    parser.add_argument("--min_score", type=float, default=0.6,
                        help="æœ€å°çª—å£é…å¯¹åˆ†æ•°ï¼ˆä½äºæ­¤å€¼çš„çª—å£è¢«è¿‡æ»¤ï¼‰")
    parser.add_argument("--train_ratio", type=float, default=0.7,
                        help="è®­ç»ƒé›†æ¯”ä¾‹")
    
    # éšæœºç§å­
    parser.add_argument("--seed", type=int, default=42,
                        help="éšæœºç§å­")
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(args.seed)
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = DatasetGenerator(
        aligned_csv=args.aligned_csv,
        results_csv=args.results_csv,
        labels_csv=args.labels_csv,
        quality_threshold=args.quality_threshold,
        min_score=args.min_score,
        train_ratio=args.train_ratio
    )
    
    # ç”Ÿæˆæ•°æ®é›†
    generator.generate_dataset(output_dir=args.output_dir)
    
    print("\nğŸ‰ æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
    print("\nä¸‹ä¸€æ­¥ï¼š")
    print("  python scripts/train_complete.py --config configs/real_binary_sota.yaml")


if __name__ == "__main__":
    main()
