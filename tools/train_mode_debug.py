#!/usr/bin/env python3
"""è®­ç»ƒæ¨¡å¼è°ƒè¯•ï¼šåŒ…å«æ¢¯åº¦+æŸå¤±"""
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parents[1] / "src"))

import torch
import yaml
from torch.utils.data import DataLoader
sys.path.insert(0, str(Path(__file__).parent.parent))
from src.avtop.models.enhanced_detector import EnhancedAVDetector
from src.avtop.data.window_dataset import WindowDataset, collate_fn
from src.avtop.losses.gram_contrastive import CompleteLossFunction

# åŠ è½½é…ç½®
with open('configs/real_binary_sota.yaml', 'r', encoding='utf-8-sig') as f:
    cfg = yaml.safe_load(f)

# åˆ›å»ºæ•°æ®é›†
dataset = WindowDataset(
    csv_path=cfg['data']['train_csv'],
    target_sr=16000,
    max_audio_length=0.3,
    max_video_frames=16
)
loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=0)

# åˆ›å»ºæ¨¡å‹å’ŒæŸå¤±
model = EnhancedAVDetector(cfg).cuda()
model.train()  # ğŸ”§ è®­ç»ƒæ¨¡å¼

criterion = CompleteLossFunction(
    num_classes=2,
    lambda_contrastive=0.3,
    lambda_kd=0.2,
    lambda_consistency=0.1
).cuda()

optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)

print("ğŸ” æ¨¡æ‹ŸçœŸå®è®­ç»ƒ...")

for batch_idx, batch in enumerate(loader):
    if batch_idx >= 100:
        break

    video = batch['video'].cuda()
    audio = batch['audio'].cuda()
    labels = batch['label'].cuda()
    is_labeled = batch['is_labeled'].cuda()

    optimizer.zero_grad()

    # å‰å‘ä¼ æ’­
    outputs = model(video, audio, return_aux=True)

    # ğŸ”§ é€ä¸ªæ£€æŸ¥è¾“å‡º
    for key, val in outputs.items():
        if isinstance(val, torch.Tensor) and torch.isnan(val).any():
            print(f"\nâŒ Batch {batch_idx}: {key} åŒ…å«nan")
            print(f"   Shape: {val.shape}")
            print(f"   Values: {val}")
            exit(1)

    # è®¡ç®—æŸå¤±
    loss_dict = criterion(outputs, labels, is_labeled)

    # ğŸ”§ æ£€æŸ¥æŸå¤±
    for key, val in loss_dict.items():
        if torch.isnan(val).any() or torch.isinf(val).any():
            print(f"\nâŒ Batch {batch_idx}: {key} å¼‚å¸¸")
            print(f"   Value: {val.item()}")

            # æ‰“å°æ‰€æœ‰æŸå¤±
            print(f"\n   æ‰€æœ‰æŸå¤±:")
            for k, v in loss_dict.items():
                print(f"     {k}: {v.item()}")

            # æ‰“å°æ¨¡å‹è¾“å‡º
            print(f"\n   æ¨¡å‹è¾“å‡º:")
            for k, v in outputs.items():
                if isinstance(v, torch.Tensor):
                    print(
                        f"     {k}: shape={v.shape}, range=[{v.min():.4f}, {v.max():.4f}], nan={torch.isnan(v).any()}")

            exit(1)

    loss = loss_dict['total_loss']

    # åå‘ä¼ æ’­
    loss.backward()

    # ğŸ”§ æ£€æŸ¥æ¢¯åº¦
    for name, param in model.named_parameters():
        if param.grad is not None and torch.isnan(param.grad).any():
            print(f"\nâŒ Batch {batch_idx}: æ¢¯åº¦åŒ…å«nan")
            print(f"   å‚æ•°: {name}")
            print(f"   æ¢¯åº¦èŒƒå›´: [{param.grad.min():.4f}, {param.grad.max():.4f}]")
            exit(1)

    optimizer.step()

    if batch_idx % 10 == 0:
        print(
            f"âœ… Batch {batch_idx}: loss={loss.item():.4f}, cls={loss_dict['classification_loss'].item():.4f}, ctr={loss_dict['contrastive_loss'].item():.4f}")

print("\nâœ… 100ä¸ªbatchè®­ç»ƒæˆåŠŸï¼Œæœªæ£€æµ‹åˆ°nan")