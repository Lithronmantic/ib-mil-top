#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_complete.py - å®Œæ•´è®­ç»ƒè„šæœ¬ï¼ˆæ— çœç•¥ï¼‰
é›†æˆæ‰€æœ‰SOTAæ–¹æ³•çš„ç«¯åˆ°ç«¯è®­ç»ƒæµç¨‹

åŠŸèƒ½ï¼š
1. Co-Attentionèåˆ
2. GRAMå¯¹æ¯”å­¦ä¹ 
3. åŒå‘KD
4. ä¸€è‡´æ€§æ­£åˆ™
5. FixMatchåŠç›‘ç£
6. å®Œæ•´checkpointç®¡ç†
7. Wandb/TensorBoardæ—¥å¿—
"""
from torch.amp import GradScaler
from contextlib import nullcontext
import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
import os

import argparse
import yaml
import time
from pathlib import Path
from typing import Dict, Optional
import numpy as np
import random

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm

# å°è¯•å¯¼å…¥wandbï¼ˆå¯é€‰ï¼‰
try:
    import wandb

    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False
    print("[Warning] wandb not installed, logging disabled")

os.environ['WANDB_API_KEY'] = '5348ec832d279c723ddbf774a64d7b1b9d4fa407'

# é¡¹ç›®æ¨¡å—å¯¼å…¥
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.avtop.models.enhanced_detector import EnhancedAVDetector
from src.avtop.data.window_dataset import WindowDataset, collate_fn
from src.avtop.losses.gram_contrastive import CompleteLossFunction


class Trainer:
    """å®Œæ•´è®­ç»ƒå™¨"""

    def __init__(self, config: Dict, output_dir: str):
        """
        Args:
            config: é…ç½®å­—å…¸
            output_dir: è¾“å‡ºç›®å½•
        """
        self.config = config
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºå­ç›®å½•
        self.checkpoints_dir = self.output_dir / "checkpoints"
        self.logs_dir = self.output_dir / "logs"
        self.checkpoints_dir.mkdir(exist_ok=True)
        self.logs_dir.mkdir(exist_ok=True)

        # è®¾å¤‡
        self.device = self._setup_device(config)

        # è®¾ç½®éšæœºç§å­
        self._set_seed(config.get('seed', 42))

        # æ¨¡å‹
        print("\n" + "=" * 70)
        print("ğŸ—¿ åˆå§‹åŒ–æ¨¡å‹")
        print("=" * 70)
        self.model = self._build_model(config)
        self.model = self.model.to(self.device)

        # æ•°æ®åŠ è½½å™¨
        print("\n" + "=" * 70)
        print("ğŸ“‚ åŠ è½½æ•°æ®é›†")
        print("=" * 70)
        self.train_loader, self.val_loader = self._build_dataloaders(config)

        # æŸå¤±å‡½æ•°
        print("\n" + "=" * 70)
        print("ğŸ¯ è®¾ç½®æŸå¤±å‡½æ•°")
        print("=" * 70)
        self.criterion = self._build_criterion(config)

        # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        print("\n" + "=" * 70)
        print("âš™ï¸ è®¾ç½®ä¼˜åŒ–å™¨")
        print("=" * 70)
        self.optimizer, self.scheduler = self._build_optimizer(config)

        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.use_amp = config.get('hardware', {}).get('mixed_precision', False)
        if self.use_amp:
            self.scaler = torch.cuda.amp.GradScaler()
            print("âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
        else:
            self.scaler = None

        # æ¢¯åº¦ç´¯ç§¯
        self.grad_accum_steps = config.get('hardware', {}).get('gradient_accumulation_steps', 1)
        if self.grad_accum_steps > 1:
            print(f"âœ… å¯ç”¨æ¢¯åº¦ç´¯ç§¯ (steps={self.grad_accum_steps})")

        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 0
        self.best_val_acc = 0.0
        self.best_val_loss = float('inf')
        self.global_step = 0

        # Wandb
        self.use_wandb = config.get('use_wandb', False) and WANDB_AVAILABLE
        if self.use_wandb:
            self._init_wandb(config)

    def _setup_device(self, config: Dict) -> torch.device:
        """è®¾ç½®è®¾å¤‡"""
        if torch.cuda.is_available():
            device = torch.device('cuda')
            print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
            print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        else:
            device = torch.device('cpu')
            print("âš ï¸ ä½¿ç”¨CPUï¼ˆè®­ç»ƒä¼šå¾ˆæ…¢ï¼‰")
        return device

    def _set_seed(self, seed: int):
        """è®¾ç½®éšæœºç§å­ï¼ˆå¯å¤ç°ï¼‰"""
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
        print(f"âœ… éšæœºç§å­è®¾ç½®ä¸º: {seed}")

    def _build_model(self, config: Dict) -> nn.Module:
        """æ„å»ºæ¨¡å‹"""
        model = EnhancedAVDetector(config)

        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

        print(f"æ¨¡å‹: EnhancedAVDetector")
        print(f"  æ€»å‚æ•°: {total_params:,}")
        print(f"  å¯è®­ç»ƒ: {trainable_params:,}")
        print(f"  èåˆç±»å‹: {model.fusion_type}")

        return model

    def _build_dataloaders(self, config: Dict):
        """æ„å»ºæ•°æ®åŠ è½½å™¨"""
        data_config = config['data']
        training_config = config['training']

        # è®­ç»ƒé›†ï¼ˆåŒ…å«æœ‰æ ‡ç­¾å’Œæ— æ ‡ç­¾ï¼‰
        train_dataset = WindowDataset(
            csv_path=data_config['train_csv'],
            target_sr=data_config.get('audio_sr', 16000),
            target_video_size=tuple(data_config.get('video_size', [224, 224])),
            max_audio_length=data_config.get('max_audio_length', 0.3),
            max_video_frames=data_config.get('max_video_frames', 16),
            cache_mode=data_config.get('cache_mode', 'none')
        )

        # éªŒè¯é›†
        val_dataset = WindowDataset(
            csv_path=data_config['val_csv'],
            target_sr=data_config.get('audio_sr', 16000),
            target_video_size=tuple(data_config.get('video_size', [224, 224])),
            max_audio_length=data_config.get('max_audio_length', 0.3),
            max_video_frames=data_config.get('max_video_frames', 16),
            cache_mode='none'
        )

        print(f"è®­ç»ƒé›†: {len(train_dataset)} çª—å£å¯¹")
        print(f"  - æœ‰æ ‡ç­¾: {sum(train_dataset.data['is_labeled'])}")
        print(f"  - æ— æ ‡ç­¾: {sum(~train_dataset.data['is_labeled'].astype(bool))}")
        print(f"éªŒè¯é›†: {len(val_dataset)} çª—å£å¯¹")

        # DataLoader
        train_loader = DataLoader(
            train_dataset,
            batch_size=training_config.get('batch_size', 8),
            shuffle=True,
            num_workers=config.get('hardware', {}).get('num_workers', 4),
            collate_fn=collate_fn,
            pin_memory=True if torch.cuda.is_available() else False,
            drop_last=True
        )

        val_loader = DataLoader(
            val_dataset,
            batch_size=training_config.get('batch_size', 8),
            shuffle=False,
            num_workers=config.get('hardware', {}).get('num_workers', 4),
            collate_fn=collate_fn,
            pin_memory=True if torch.cuda.is_available() else False
        )

        print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")

        return train_loader, val_loader

    def _build_criterion(self, config: Dict):
        """æ„å»ºæŸå¤±å‡½æ•°"""
        loss_config = config.get('loss', {})

        criterion = CompleteLossFunction(
            num_classes=config['model']['num_classes'],
            lambda_contrastive=loss_config.get('lambda_contrastive', 0.3),
            lambda_kd=loss_config.get('lambda_kd', 0.2),
            lambda_consistency=loss_config.get('lambda_consistency', 0.1),
            temperature=loss_config.get('temperature', 0.07),
            kd_temperature=loss_config.get('kd_temperature', 4.0)
        )

        print("æŸå¤±å‡½æ•°: CompleteLossFunction")
        print(f"  - å¯¹æ¯”å­¦ä¹ æƒé‡: {loss_config.get('lambda_contrastive', 0.3)}")
        print(f"  - KDæƒé‡: {loss_config.get('lambda_kd', 0.2)}")
        print(f"  - ä¸€è‡´æ€§æƒé‡: {loss_config.get('lambda_consistency', 0.1)}")

        return criterion.to(self.device)

    def _build_optimizer(self, config: Dict):
        """æ„å»ºä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        training_config = config['training']

        # ä¼˜åŒ–å™¨
        optimizer_type = training_config.get('optimizer', 'adamw').lower()
        lr = training_config.get('learning_rate', 1e-5)  # ğŸ”§ é»˜è®¤é™ä½åˆ°1e-5
        weight_decay = training_config.get('weight_decay', 1e-4)

        if optimizer_type == 'adamw':
            optimizer = optim.AdamW(
                self.model.parameters(),
                lr=lr,
                weight_decay=weight_decay,
                betas=(0.9, 0.999)
            )
        elif optimizer_type == 'adam':
            optimizer = optim.Adam(
                self.model.parameters(),
                lr=lr,
                weight_decay=weight_decay
            )
        elif optimizer_type == 'sgd':
            optimizer = optim.SGD(
                self.model.parameters(),
                lr=lr,
                momentum=0.9,
                weight_decay=weight_decay
            )
        else:
            raise ValueError(f"Unknown optimizer: {optimizer_type}")

        print(f"ä¼˜åŒ–å™¨: {optimizer_type.upper()}")
        print(f"  - å­¦ä¹ ç‡: {lr}")
        print(f"  - æƒé‡è¡°å‡: {weight_decay}")

        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler_type = training_config.get('scheduler', 'cosine').lower()
        num_epochs = training_config.get('num_epochs', 100)

        if scheduler_type == 'cosine':
            scheduler = optim.lr_scheduler.CosineAnnealingLR(
                optimizer,
                T_max=num_epochs,
                eta_min=lr * 0.01
            )
        elif scheduler_type == 'step':
            scheduler = optim.lr_scheduler.StepLR(
                optimizer,
                step_size=training_config.get('step_size', 30),
                gamma=training_config.get('gamma', 0.1)
            )
        elif scheduler_type == 'plateau':
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                optimizer,
                mode='min',
                factor=0.5,
                patience=10,
                verbose=True
            )
        else:
            scheduler = None

        if scheduler:
            print(f"å­¦ä¹ ç‡è°ƒåº¦: {scheduler_type}")

        return optimizer, scheduler

    def _init_wandb(self, config: Dict):
        """åˆå§‹åŒ–Wandb"""
        wandb.init(
            project=config.get('wandb_project', 'avtop-training'),
            name=config.get('wandb_name', f'run_{int(time.time())}'),
            config=config,
            dir=str(self.logs_dir)
        )
        wandb.watch(self.model, log='all', log_freq=100)
        print("âœ… Wandbå·²åˆå§‹åŒ–")

    def train_epoch(self, epoch: int):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()

        epoch_loss = 0.0
        epoch_cls_loss = 0.0
        epoch_ctr_loss = 0.0
        epoch_kd_loss = 0.0
        epoch_cons_loss = 0.0

        num_batches = len(self.train_loader)

        # è¿›åº¦æ¡
        pbar = tqdm(
            self.train_loader,
            desc=f"Epoch {epoch}/{self.config['training']['num_epochs']}",
            ncols=100
        )

        for batch_idx, batch in enumerate(pbar):
            # æ•°æ®ç§»åˆ°è®¾å¤‡
            video = batch['video'].to(self.device)
            audio = batch['audio'].to(self.device)
            labels = batch['label'].to(self.device)
            is_labeled = batch['is_labeled'].to(self.device)

            # ğŸ”§ æ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰nan
            if torch.isnan(video).any() or torch.isnan(audio).any():
                print(f"âš ï¸ è¾“å…¥åŒ…å«nanï¼Œè·³è¿‡æ­¤batch")
                continue

            # å‰å‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰
            if self.use_amp:
                amp_ctx = torch.amp.autocast('cuda') if self.device.type == 'cuda' else nullcontext()
                with amp_ctx:
                    outputs = self.model(video, audio, return_aux=True)

                    # ğŸ”§ æ£€æŸ¥è¾“å‡ºæ˜¯å¦æœ‰nan
                    if torch.isnan(outputs['clip_logits']).any():
                        print(f"âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«nanï¼Œè·³è¿‡æ­¤batch")
                        continue

                    loss_dict = self.criterion(outputs, labels, is_labeled)
                    loss = loss_dict['total_loss']

                    # ğŸ”§ æ£€æŸ¥æŸå¤±æ˜¯å¦æœ‰nan
                    if torch.isnan(loss).any() or torch.isinf(loss).any():
                        print(f"âš ï¸ æŸå¤±ä¸ºnan/inf: {loss.item()}")
                        continue

                    loss = loss / self.grad_accum_steps

                # åå‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰
                self.scaler.scale(loss).backward()

                # æ¢¯åº¦ç´¯ç§¯
                if (batch_idx + 1) % self.grad_accum_steps == 0:
                    self.scaler.unscale_(self.optimizer)
                    # ğŸ”§ æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad()

            else:
                # æ ‡å‡†è®­ç»ƒ
                outputs = self.model(video, audio, return_aux=True)

                # ğŸ”§ æ£€æŸ¥è¾“å‡ºæ˜¯å¦æœ‰nan
                if torch.isnan(outputs['clip_logits']).any():
                    print(f"âš ï¸ æ¨¡å‹è¾“å‡ºåŒ…å«nanï¼Œè·³è¿‡æ­¤batch")
                    continue

                loss_dict = self.criterion(outputs, labels, is_labeled)
                loss = loss_dict['total_loss']

                # ğŸ”§ æ£€æŸ¥æŸå¤±æ˜¯å¦æœ‰nan
                if torch.isnan(loss).any() or torch.isinf(loss).any():
                    print(f"âš ï¸ æŸå¤±ä¸ºnan/inf: {loss.item()}")
                    continue

                loss = loss / self.grad_accum_steps

                # åå‘ä¼ æ’­
                loss.backward()

                # æ¢¯åº¦ç´¯ç§¯
                if (batch_idx + 1) % self.grad_accum_steps == 0:
                    # ğŸ”§ æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                    self.optimizer.step()
                    self.optimizer.zero_grad()

            # ç´¯ç§¯æŸå¤±
            epoch_loss += loss_dict['total_loss'].item()
            epoch_cls_loss += loss_dict['classification_loss'].item()
            epoch_ctr_loss += loss_dict['contrastive_loss'].item()
            epoch_kd_loss += loss_dict['kd_loss'].item()
            epoch_cons_loss += loss_dict['consistency_loss'].item()

            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'loss': f"{loss_dict['total_loss'].item():.4f}",
                'cls': f"{loss_dict['classification_loss'].item():.4f}",
                'ctr': f"{loss_dict['contrastive_loss'].item():.4f}"
            })

            # è®°å½•åˆ°Wandb
            self.global_step += 1
            if self.use_wandb and self.global_step % 10 == 0:
                wandb.log({
                    'train/loss': loss_dict['total_loss'].item(),
                    'train/cls_loss': loss_dict['classification_loss'].item(),
                    'train/ctr_loss': loss_dict['contrastive_loss'].item(),
                    'train/kd_loss': loss_dict['kd_loss'].item(),
                    'train/cons_loss': loss_dict['consistency_loss'].item(),
                    'train/lr': self.optimizer.param_groups[0]['lr'],
                    'global_step': self.global_step
                })

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = epoch_loss / num_batches
        avg_cls_loss = epoch_cls_loss / num_batches
        avg_ctr_loss = epoch_ctr_loss / num_batches
        avg_kd_loss = epoch_kd_loss / num_batches
        avg_cons_loss = epoch_cons_loss / num_batches

        return {
            'loss': avg_loss,
            'cls_loss': avg_cls_loss,
            'ctr_loss': avg_ctr_loss,
            'kd_loss': avg_kd_loss,
            'cons_loss': avg_cons_loss
        }

    def validate(self, epoch: int):
        """éªŒè¯"""
        self.model.eval()

        val_loss = 0.0
        all_preds = []
        all_labels = []

        with torch.no_grad():
            for batch in tqdm(self.val_loader, desc="Validation", ncols=100):
                video = batch['video'].to(self.device)
                audio = batch['audio'].to(self.device)
                labels = batch['label'].to(self.device)
                is_labeled = batch['is_labeled'].to(self.device)

                # å‰å‘ä¼ æ’­
                outputs = self.model(video, audio, return_aux=True)
                loss_dict = self.criterion(outputs, labels, is_labeled)

                val_loss += loss_dict['total_loss'].item()

                # ğŸ”§ ä½¿ç”¨æ­£ç¡®çš„keyè·å–logits
                clip_logits = outputs['clip_logits']
                preds = torch.argmax(clip_logits, dim=1)

                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

        # è®¡ç®—æŒ‡æ ‡
        avg_val_loss = val_loss / len(self.val_loader)

        all_preds = np.array(all_preds)
        all_labels = np.array(all_labels)

        accuracy = (all_preds == all_labels).mean()

        # æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
        class_acc = {}
        for c in range(self.config['model']['num_classes']):
            mask = all_labels == c
            if mask.sum() > 0:
                class_acc[f'class_{c}'] = (all_preds[mask] == all_labels[mask]).mean()

        metrics = {
            'val_loss': avg_val_loss,
            'val_accuracy': accuracy,
            **class_acc
        }

        # è®°å½•åˆ°Wandb
        if self.use_wandb:
            wandb.log({
                'val/loss': avg_val_loss,
                'val/accuracy': accuracy,
                **{f'val/{k}': v for k, v in class_acc.items()},
                'epoch': epoch
            })

        return metrics

    def save_checkpoint(self, epoch: int, is_best: bool = False):
        """ä¿å­˜checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_val_acc': self.best_val_acc,
            'best_val_loss': self.best_val_loss,
            'config': self.config
        }

        if self.scheduler:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()

        # ä¿å­˜æœ€æ–°checkpoint
        latest_path = self.checkpoints_dir / f"checkpoint_epoch{epoch}.pth"
        torch.save(checkpoint, latest_path)
        print(f"ğŸ’¾ Checkpointå·²ä¿å­˜: {latest_path}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = self.checkpoints_dir / "best_model.pth"
            torch.save(checkpoint, best_path)
            print(f"ğŸ† æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}")

        # åˆ é™¤æ—§çš„checkpointï¼ˆä¿ç•™æœ€è¿‘5ä¸ªï¼‰
        checkpoints = sorted(self.checkpoints_dir.glob("checkpoint_epoch*.pth"))
        if len(checkpoints) > 5:
            for ckpt in checkpoints[:-5]:
                ckpt.unlink()

    def load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½checkpoint"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)

        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        if self.scheduler and 'scheduler_state_dict' in checkpoint:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

        self.current_epoch = checkpoint['epoch']
        self.best_val_acc = checkpoint.get('best_val_acc', 0.0)
        self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))

        print(f"âœ… Checkpointå·²åŠ è½½: {checkpoint_path}")
        print(f"   æ¢å¤åˆ°Epoch {self.current_epoch}")
        print(f"   æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_acc:.4f}")

    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        num_epochs = self.config['training']['num_epochs']
        start_epoch = self.current_epoch + 1

        print("\n" + "=" * 70)
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ (Epoch {start_epoch} - {num_epochs})")
        print("=" * 70)

        for epoch in range(start_epoch, num_epochs + 1):
            self.current_epoch = epoch

            # è®­ç»ƒ
            train_metrics = self.train_epoch(epoch)

            # éªŒè¯
            val_metrics = self.validate(epoch)

            # å­¦ä¹ ç‡è°ƒåº¦
            if self.scheduler:
                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    self.scheduler.step(val_metrics['val_loss'])
                else:
                    self.scheduler.step()

            # æ‰“å°ç»“æœ
            print(f"\n" + "=" * 70)
            print(f"Epoch {epoch}/{num_epochs} æ€»ç»“")
            print("=" * 70)
            print(f"è®­ç»ƒæŸå¤±: {train_metrics['loss']:.4f}")
            print(f"  - åˆ†ç±»: {train_metrics['cls_loss']:.4f}")
            print(f"  - å¯¹æ¯”: {train_metrics['ctr_loss']:.4f}")
            print(f"  - KD: {train_metrics['kd_loss']:.4f}")
            print(f"  - ä¸€è‡´æ€§: {train_metrics['cons_loss']:.4f}")
            print(f"éªŒè¯æŸå¤±: {val_metrics['val_loss']:.4f}")
            print(f"éªŒè¯å‡†ç¡®ç‡: {val_metrics['val_accuracy']:.4f}")
            for k, v in val_metrics.items():
                if k.startswith('class_'):
                    print(f"  - {k}: {v:.4f}")
            print(f"å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")

            # ä¿å­˜checkpoint
            is_best = val_metrics['val_accuracy'] > self.best_val_acc
            if is_best:
                self.best_val_acc = val_metrics['val_accuracy']
                self.best_val_loss = val_metrics['val_loss']
                print(f"ğŸ‰ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {self.best_val_acc:.4f}")

            if epoch % self.config['training'].get('save_every', 5) == 0 or is_best:
                self.save_checkpoint(epoch, is_best=is_best)

            print("=" * 70 + "\n")

        print("âœ… è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.best_val_acc:.4f}")

        if self.use_wandb:
            wandb.finish()


def main():
    parser = argparse.ArgumentParser(description="å®Œæ•´è®­ç»ƒè„šæœ¬")
    parser.add_argument('--config', required=True, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', default=None, help='æ¢å¤è®­ç»ƒçš„checkpointè·¯å¾„')
    parser.add_argument('--output_dir', default='outputs/sota_training', help='è¾“å‡ºç›®å½•')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    with open(args.config, 'r', encoding='utf-8-sig') as f:
        config = yaml.safe_load(f)

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(config, args.output_dir)

    # æ¢å¤è®­ç»ƒ
    if args.resume:
        trainer.load_checkpoint(args.resume)

    # å¼€å§‹è®­ç»ƒ
    try:
        trainer.train()
    except KeyboardInterrupt:
        print("\nâ›” è®­ç»ƒè¢«ä¸­æ–­")
        # ä¿å­˜æœ€åçš„checkpoint
        trainer.save_checkpoint(trainer.current_epoch, is_best=False)
        print("ğŸ’¾ å·²ä¿å­˜å½“å‰checkpoint")


if __name__ == "__main__":
    main()