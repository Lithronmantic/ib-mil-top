# scripts/train_baseline.py
"""
æœ€ä¿å®ˆçš„baselineè®­ç»ƒè„šæœ¬
ç”¨æ ‡å‡†CrossEntropy + ç®€å•çš„pos_weightï¼Œä¸ä½¿ç”¨ä»»ä½•é«˜çº§æŠ€å·§
ç›®çš„ï¼šéªŒè¯æ•°æ®å’Œæ¨¡å‹æ˜¯å¦èƒ½å­¦åˆ°åŸºæœ¬æ¨¡å¼
"""
import argparse
import yaml
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).resolve().parents[1] / "src"))

from torch.utils.data import DataLoader
from collections import defaultdict

from avtop.models.enhanced_detector import EnhancedAVTopDetector
from avtop.data.csv_dataset import BinaryAVCSVDataset, collate as csv_collate
from avtop.eval.enhanced_metrics import validate_model, ImbalancedMetricsCalculator
from avtop.utils.experiment import ExperimentManager


def compute_class_stats(csv_path):
    """è®¡ç®—ç±»åˆ«ç»Ÿè®¡"""
    import csv
    n_pos = n_neg = 0
    with open(csv_path, "r", encoding="utf-8") as f:
        for row in csv.DictReader(f):
            if int(row["label"]) == 1:
                n_pos += 1
            else:
                n_neg += 1

    minority_class = 0 if n_neg < n_pos else 1
    pos_weight = n_neg / n_pos if n_pos > 0 else 1.0

    return n_pos, n_neg, minority_class, pos_weight


def make_simple_loader(csv_path, cfg, shuffle=True):
    """åˆ›å»ºç®€å•çš„æ•°æ®åŠ è½½å™¨ï¼ˆæ— åŠ æƒé‡‡æ ·ï¼‰"""
    ds = BinaryAVCSVDataset(
        csv_path,
        root=cfg["data"].get("root", ""),
        T_v=cfg["data"]["T_v"],
        T_a=cfg["data"]["T_a"],
        mel_bins=cfg["data"]["mel"],
        sample_rate=cfg["data"]["sr"]
    )

    return DataLoader(
        ds,
        batch_size=cfg["train"]["batch_size"],
        shuffle=shuffle,
        collate_fn=csv_collate,
        num_workers=cfg["train"].get("workers", 4),
        pin_memory=True
    )


def main(cfg):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # å®éªŒç®¡ç†
    exp_name = cfg["experiment"]["name"] + "_baseline"
    mgr = ExperimentManager(cfg["experiment"]["workdir"], exp_name)
    mgr.save_config(cfg)

    # æ•°æ®å‡†å¤‡
    train_csv = cfg["data"]["train_csv"]
    val_csv = cfg["data"]["val_csv"]

    n_pos, n_neg, minority_class, pos_weight = compute_class_stats(train_csv)

    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š Baseline Training Configuration")
    print(f"{'=' * 60}")
    print(f"Minority class: label={minority_class}")
    print(f"  label=0: {n_neg} samples ({n_neg / (n_pos + n_neg):.2%})")
    print(f"  label=1: {n_pos} samples ({n_pos / (n_pos + n_neg):.2%})")
    print(f"pos_weight: {pos_weight:.3f}")
    print(f"\nğŸ¯ Training strategy:")
    print(f"  Loss: Weighted CrossEntropy (simplest)")
    print(f"  Sampling: Random (no weighted sampling)")
    print(f"  LR: Constant (no scheduler)")
    print(f"  Goal: Verify if model can learn basic patterns")
    print(f"{'=' * 60}\n")

    # æ•°æ®åŠ è½½å™¨ï¼ˆéšæœºé‡‡æ ·ï¼‰
    train_loader = make_simple_loader(train_csv, cfg, shuffle=True)
    val_loader = make_simple_loader(val_csv, cfg, shuffle=False)

    # åˆ›å»ºæ¨¡å‹
    model = EnhancedAVTopDetector(cfg).to(device)

    # â­ æœ€ç®€å•çš„æŸå¤±ï¼šWeighted CrossEntropy
    # åªå¯¹æ­£ç±»ï¼ˆlabel=1ï¼‰åŠ æƒ
    class_weights = torch.tensor([1.0, pos_weight], device=device)
    criterion = nn.CrossEntropyLoss(weight=class_weights)

    print(f"Loss function: CrossEntropy with weights = {class_weights.cpu().numpy()}")

    # ä¼˜åŒ–å™¨ï¼šAdamWï¼Œå•ä¸€å­¦ä¹ ç‡
    lr = 1e-4  # è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œæ›´ä¿å®ˆ
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)

    # è®­ç»ƒé…ç½®
    epochs = cfg["train"].get("epochs", 50)
    patience = cfg["train"].get("patience", 15)

    best_auprc = 0.0
    bad_epochs = 0

    print(f"Starting baseline training...")
    print(f"  LR: {lr:.2e}")
    print(f"  Epochs: {epochs}")
    print(f"  Patience: {patience}\n")

    # è®­ç»ƒå¾ªç¯
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0.0
        n_batches = 0

        # è®°å½•é¢„æµ‹åˆ†å¸ƒï¼ˆç”¨äºè¯Šæ–­ï¼‰
        train_preds_pos = 0
        train_preds_neg = 0

        for batch_idx, batch in enumerate(train_loader):
            video = batch["video"].to(device)
            audio = batch["audio"].to(device)
            labels = batch["label_idx"].to(device)

            # å‰å‘ä¼ æ’­
            out = model(video, audio)
            logits = out['clip_logits']  # (B, 2)

            # è®¡ç®—æŸå¤±ï¼ˆæœ€ç®€å•ï¼‰
            loss = criterion(logits, labels)

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            # è®°å½•
            epoch_loss += loss.item()
            n_batches += 1

            # ç»Ÿè®¡é¢„æµ‹åˆ†å¸ƒ
            with torch.no_grad():
                probs = torch.softmax(logits, dim=-1)
                preds = torch.argmax(probs, dim=-1)
                train_preds_pos += (preds == 1).sum().item()
                train_preds_neg += (preds == 0).sum().item()

            if batch_idx % 10 == 0:
                print(f'[epoch {epoch}][{batch_idx}/{len(train_loader)}] loss: {loss.item():.4f}')

        epoch_loss /= n_batches

        # æ‰“å°è®­ç»ƒé›†é¢„æµ‹åˆ†å¸ƒï¼ˆè¯Šæ–­ç”¨ï¼‰
        total_train = train_preds_pos + train_preds_neg
        print(f"\n[epoch {epoch}] Train predictions:")
        print(f"  Pred as 0: {train_preds_neg} ({train_preds_neg / total_train:.2%})")
        print(f"  Pred as 1: {train_preds_pos} ({train_preds_pos / total_train:.2%})")
        print(f"  Avg loss: {epoch_loss:.4f}")

        # éªŒè¯
        val_metrics, val_probs, val_labels = validate_model(
            model, val_loader, device, minority_class=minority_class
        )

        # ç®€åŒ–æŠ¥å‘Š
        print(f"\n[epoch {epoch}] Validation:")
        print(
            f"  AUPRC: {val_metrics['auprc_minority']:.4f} (baseline: {val_metrics['auprc_baseline']:.4f}, gain: {val_metrics['auprc_gain']:.4f})")
        print(f"  MCC: {val_metrics['mcc']:.4f}")
        print(f"  Precision: {val_metrics['precision_minority']:.4f}, Recall: {val_metrics['recall_minority']:.4f}")
        print(f"  Specificity: {val_metrics['specificity']:.4f}")

        # æ‰“å°æ··æ·†çŸ©é˜µ
        print(f"  Confusion Matrix:")
        print(f"    TN={val_metrics['tn']}, FP={val_metrics['fp']}")
        print(f"    FN={val_metrics['fn']}, TP={val_metrics['tp']}")

        # ä¿å­˜æŒ‡æ ‡
        mgr.save_metrics({
            'epoch': epoch,
            **val_metrics,
            'train_loss': epoch_loss
        }, epoch)

        # æ—©åœï¼ˆåŸºäºAUPRCï¼‰
        current_auprc = val_metrics['auprc_minority']

        if current_auprc > best_auprc:
            best_auprc = current_auprc
            bad_epochs = 0

            mgr.save_checkpoint({
                'model': model.state_dict(),
                'optimizer': optimizer.state_dict(),
                'epoch': epoch,
                'best_auprc': best_auprc,
                'minority_class': minority_class,
                'config': cfg
            }, epoch, fname="best_model.pth")

            print(f"  â­ New best AUPRC: {best_auprc:.4f}")
        else:
            bad_epochs += 1
            print(f"  No improvement ({bad_epochs}/{patience})")

        print()

        if bad_epochs >= patience:
            print(f"ğŸ›‘ Early stopping at epoch {epoch}")
            break

    print(f"\nğŸ‰ Baseline training finished!")
    print(f"Best AUPRC: {best_auprc:.4f}")

    # æœ€ç»ˆè¯Šæ–­å»ºè®®
    print(f"\n{'=' * 60}")
    print("Diagnostic Summary")
    print(f"{'=' * 60}")

    if best_auprc < 0.25:  # ä½äºbaselineï¼ˆå‡è®¾baselineâ‰ˆ0.20ï¼‰
        print("âŒ Model failed to learn")
        print("   AUPRC is not better than baseline")
        print("\n   Possible issues:")
        print("   1. Data quality: labels may be incorrect")
        print("   2. Features insufficient: audio/video don't contain discriminative info")
        print("   3. Model capacity: architecture may be inadequate")
        print("\n   Next steps:")
        print("   âœ… Run diagnostic script to check model outputs")
        print("   âœ… Manually inspect some samples to verify labels")
        print("   âœ… Try simpler features (e.g., only video or only audio)")

    elif best_auprc < 0.40:
        print("âš ï¸  Model shows weak learning")
        print(f"   AUPRC gain: {best_auprc - 0.20:.4f}")
        print("\n   Next steps:")
        print("   âœ… Try Focal Loss with gamma=1.0 (mild)")
        print("   âœ… Add data augmentation")
        print("   âœ… Increase model capacity")

    else:
        print("âœ… Model shows good learning!")
        print(f"   AUPRC gain: {best_auprc - 0.20:.4f}")
        print("\n   Next steps:")
        print("   âœ… Now try Focal Loss / CB Loss for better performance")
        print("   âœ… Add weighted sampling")
        print("   âœ… Fine-tune hyperparameters")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, default="configs/real_binary.yaml")
    args = parser.parse_args()

    with open(args.config, 'r') as f:
        cfg = yaml.safe_load(f)

    main(cfg)