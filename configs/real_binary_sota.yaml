# =============================================================================
# å®Œæ•´é…ç½®æ–‡ä»¶ - Intelç„Šæ¥æ•°æ®é›†SOTAè®­ç»ƒ
# =============================================================================

# -----------------------------------------------------------------------------
# å®éªŒå…ƒä¿¡æ¯
# -----------------------------------------------------------------------------
experiment_name: "intel_welding_sota"
description: "å®Œæ•´SOTAæ–¹æ³•é›†æˆï¼šCo-Attention + GRAM + KD + Consistency + FixMatch"
version: "1.0"
seed: 42

# -----------------------------------------------------------------------------
# Wandbæ—¥å¿—ï¼ˆå¯é€‰ï¼‰
# -----------------------------------------------------------------------------
use_wandb: true
wandb_project: "avtop-training"
wandb_name: "intel_welding_coattn_gram"  # ä¼šè‡ªåŠ¨æ·»åŠ æ—¶é—´æˆ³

# -----------------------------------------------------------------------------
# æ•°æ®é…ç½®
# -----------------------------------------------------------------------------
data:
  train_csv: "data/full_dataset.csv"   # â† æ”¹è¿™é‡Œ
  val_csv:   "data/val.csv"
  unlabeled_csv: "data/unlabeled.csv"  # ä¿ç•™æ— å¦¨ï¼Œä½†å½“å‰è„šæœ¬ä¸ä¼šè¯»
  num_classes: 2
  class_names: ["Good", "Defect"]
  audio_sr: 16000
  max_audio_length: 0.3
  video_size: [224, 224]
  max_video_frames: 16
  cache_mode: "none"


# -----------------------------------------------------------------------------
# æ¨¡å‹é…ç½®
# -----------------------------------------------------------------------------
model:
  # Backboneé€‰æ‹©
  video_backbone: "resnet18_2d"  # é€‰é¡¹: resnet18_2d, resnet50_2d, r2plus1d
  audio_backbone: "mel_spectrogram_cnn"  # é€‰é¡¹: mel_spectrogram_cnn, vggish

  # ç‰¹å¾ç»´åº¦ï¼ˆbackboneè¾“å‡ºï¼‰
  video_dim: 512
  audio_dim: 128

  # ç±»åˆ«æ•°
  num_classes: 2

  # Pretrainedæƒé‡
  pretrained: true

  # è¾…åŠ©åˆ†ç±»å¤´ï¼ˆç”¨äºKDï¼‰
  use_aux_heads: true

# æ—¶åºç¼–ç å™¨é…ç½®ï¼ˆå¯é€‰ï¼‰
use_temporal_encoder: true
temporal_hidden_dim: 256
temporal_layers: 1

# -----------------------------------------------------------------------------
# èåˆé…ç½®ï¼ˆå…³é”®ï¼ï¼‰
# -----------------------------------------------------------------------------
fusion:
  type: "coattention"  # é€‰é¡¹: cfa, ib, coattention

  # Co-Attentionä¸“ç”¨å‚æ•°
  d_model: 256  # èåˆåçš„ç‰¹å¾ç»´åº¦
  bottleneck_dim: 32  # Attention Bottleneckç»´åº¦ï¼ˆè¶Šå°è¶Šå¿«ï¼Œå»ºè®®16-64ï¼‰
  num_layers: 2  # Co-Attentionå±‚æ•°
  num_heads: 8  # å¤šå¤´æ³¨æ„åŠ›å¤´æ•°
  dropout: 0.1

  # CFA/IBä¸“ç”¨å‚æ•°ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
  beta: 0.1  # Information Bottleneckçš„Î²å‚æ•°

# -----------------------------------------------------------------------------
# æŸå¤±å‡½æ•°é…ç½®
# -----------------------------------------------------------------------------
loss:
  lambda_contrastive: 0.3
  lambda_kd: 0.2
  lambda_consistency: 0.1   # â† è‹¥æ— æ ‡ç­¾åˆ©ç”¨ç‡åä½/æ‹Ÿåˆä¸åŠ¨ï¼Œå¯å…ˆå‡åˆ° 0.3 è§‚å¯Ÿ
  temperature: 0.07
  kd_temperature: 4.0
# -----------------------------------------------------------------------------
# è®­ç»ƒé…ç½®
# -----------------------------------------------------------------------------
training:
  # åŸºæœ¬å‚æ•°
  num_epochs: 1
  batch_size: 8  # å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œé™åˆ°4

  # æœ‰æ ‡ç­¾/æ— æ ‡ç­¾æ‰¹æ¬¡æ¯”ä¾‹ï¼ˆç”¨äºåŠç›‘ç£ï¼‰
  labeled_batch_size: 4
  unlabeled_batch_size: 4

  # ä¼˜åŒ–å™¨
  optimizer: "adamw"  # é€‰é¡¹: adam, adamw, sgd
  learning_rate: 1.0e-4
  weight_decay: 1.0e-2

  # å­¦ä¹ ç‡è°ƒåº¦
  scheduler: "cosine"  # é€‰é¡¹: cosine, step, plateau, none
  step_size: 30  # StepLRä¸“ç”¨
  gamma: 0.1  # StepLRä¸“ç”¨

  # ä¿å­˜ç­–ç•¥
  save_every: 5  # æ¯Nä¸ªepochä¿å­˜ä¸€æ¬¡
  keep_last_n: 5  # ä¿ç•™æœ€è¿‘Nä¸ªcheckpoint

  # æ—©åœï¼ˆå¯é€‰ï¼‰
  early_stopping: false
  patience: 15

# -----------------------------------------------------------------------------
# åŠç›‘ç£å­¦ä¹ é…ç½®ï¼ˆFixMatchï¼‰
# -----------------------------------------------------------------------------
semi_supervised:
  enable: true

  # ä¼ªæ ‡ç­¾
  confidence_threshold: 0.95  # ä¼ªæ ‡ç­¾ç½®ä¿¡åº¦é˜ˆå€¼
  pseudo_label_warmup: 10  # å‰Nä¸ªepochä¸ä½¿ç”¨ä¼ªæ ‡ç­¾

  # å¼ºå¼±å¢å¼º
  weak_augmentation: true
  strong_augmentation: true

  # FixMatchæƒé‡
  lambda_unsup: 1.0  # æ— ç›‘ç£æŸå¤±æƒé‡

# -----------------------------------------------------------------------------
# ç¡¬ä»¶é…ç½®
# -----------------------------------------------------------------------------
hardware:
  # GPUè®¾ç½®
  use_cuda: true
  device_ids: [0]  # GPU IDåˆ—è¡¨ï¼Œå•å¡è®­ç»ƒç”¨[0]

  # å¤šGPUï¼ˆDataParallelï¼‰
  use_multi_gpu: false

  # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16ï¼ŒèŠ‚çœæ˜¾å­˜ï¼‰
  mixed_precision: false

  # DataLoader
  num_workers: 4  # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
  pin_memory: true  # å›ºå®šå†…å­˜ï¼ˆåŠ é€ŸCPU->GPUä¼ è¾“ï¼‰

  # æ¢¯åº¦ç´¯ç§¯ï¼ˆå˜ç›¸å¢å¤§batch sizeï¼‰
  gradient_accumulation_steps: 1  # è®¾ä¸º2ç›¸å½“äºbatch_sizeç¿»å€

# -----------------------------------------------------------------------------
# è°ƒè¯•ä¸æ—¥å¿—
# -----------------------------------------------------------------------------
debug:
  enable: false  # è°ƒè¯•æ¨¡å¼ï¼ˆåªè¿è¡Œå°‘é‡batchï¼‰
  max_batches: 5  # è°ƒè¯•æ¨¡å¼ä¸‹æ¯ä¸ªepochæœ€å¤šè¿è¡Œçš„batchæ•°

logging:
  log_interval: 10  # æ¯Nä¸ªbatchæ‰“å°ä¸€æ¬¡æ—¥å¿—
  save_images: false  # æ˜¯å¦ä¿å­˜å¯è§†åŒ–å›¾åƒ

  # TensorBoardï¼ˆå¤‡é€‰ï¼‰
  use_tensorboard: false
  tensorboard_dir: "runs/sota_training"

# -----------------------------------------------------------------------------
# æ•°æ®å¢å¼ºé…ç½®ï¼ˆå·¥ä¸šçº§ï¼‰
# -----------------------------------------------------------------------------
augmentation:
  audio:
    # SpecAugment
    freq_mask_num: 2
    freq_mask_param: 27
    time_mask_num: 2
    time_mask_param: 40

    # æ—¶åŸŸå¢å¼º
    time_stretch: true
    time_stretch_rate: [0.8, 1.2]

    pitch_shift: true
    pitch_shift_steps: [-2, 2]

    # å™ªå£°
    add_noise: true
    noise_factor: 0.005

  video:
    # ç©ºé—´å¢å¼º
    random_crop: true
    random_flip: true
    color_jitter: true

    # æ—¶åºå¢å¼º
    random_temporal_crop: true

    # MixUp/CutMixï¼ˆå¯é€‰ï¼‰
    use_mixup: false
    mixup_alpha: 0.2

    use_cutmix: false
    cutmix_alpha: 1.0

# -----------------------------------------------------------------------------
# è¯„ä¼°é…ç½®
# -----------------------------------------------------------------------------
evaluation:
  # è¯„ä¼°æŒ‡æ ‡
  metrics: ["accuracy", "precision", "recall", "f1", "auc"]

  # æ··æ·†çŸ©é˜µ
  save_confusion_matrix: true

  # æ³¨æ„åŠ›å¯è§†åŒ–
  visualize_attention: true
  num_vis_samples: 10

  # å•æ¨¡æ€å¯¹æ¯”
  evaluate_modalities: true  # è¯„ä¼°Audio-only, Video-only, Fusion

# -----------------------------------------------------------------------------
# é«˜çº§é…ç½®
# -----------------------------------------------------------------------------
advanced:
  # å†»ç»“backboneï¼ˆå‰Nä¸ªepochï¼‰
  freeze_backbone_epochs: 0

  # æ¢¯åº¦è£å‰ª
  gradient_clip: 1.0

  # æ ‡ç­¾å¹³æ»‘
  label_smoothing: 0.0

  # Dropoutè°ƒåº¦ï¼ˆé€æ¸å‡å°ï¼‰
  dropout_schedule: false
  initial_dropout: 0.5
  final_dropout: 0.1

# -----------------------------------------------------------------------------
# è·¯å¾„é…ç½®
# -----------------------------------------------------------------------------
paths:
  # è¾“å‡ºç›®å½•
  output_dir: "outputs/sota_training"

  # Checkpointç›®å½•
  checkpoint_dir: "outputs/sota_training/checkpoints"

  # æ—¥å¿—ç›®å½•
  log_dir: "outputs/sota_training/logs"

  # å¯è§†åŒ–ç›®å½•
  vis_dir: "outputs/sota_training/visualizations"

# -----------------------------------------------------------------------------
# è¶…å‚æ•°è°ƒä¼˜å»ºè®®
# -----------------------------------------------------------------------------
# å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå°è¯•è°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š
#
# ğŸ”¥ æ˜¾å­˜ä¸è¶³ï¼š
#   - training.batch_size: 8 â†’ 4
#   - data.max_video_frames: 16 â†’ 8
#   - fusion.bottleneck_dim: 32 â†’ 16
#   - hardware.mixed_precision: true
#   - hardware.gradient_accumulation_steps: 2
#
# ğŸ“‰ è®­ç»ƒä¸æ”¶æ•›ï¼š
#   - training.learning_rate: 1e-4 â†’ 1e-5
#   - loss.lambda_contrastive: 0.3 â†’ 0.1
#   - loss.lambda_kd: 0.2 â†’ 0.1
#   - semi_supervised.confidence_threshold: 0.95 â†’ 0.90
#
# â±ï¸ è®­ç»ƒå¤ªæ…¢ï¼š
#   - fusion.bottleneck_dim: 32 â†’ 16
#   - fusion.num_layers: 2 â†’ 1
#   - data.max_video_frames: 16 â†’ 8
#   - hardware.num_workers: 4 â†’ 8
#
# ğŸ¯ è¿‡æ‹Ÿåˆï¼š
#   - fusion.dropout: 0.1 â†’ 0.3
#   - training.weight_decay: 1e-4 â†’ 1e-3
#   - augmentationå¼ºåº¦å¢åŠ 
#   - advanced.label_smoothing: 0.0 â†’ 0.1
#
# ğŸ¯ æ¬ æ‹Ÿåˆï¼š
#   - training.num_epochs: 100 â†’ 200
#   - fusion.num_layers: 2 â†’ 3
#   - fusion.dropout: 0.1 â†’ 0.05
#   - training.learning_rate: 1e-4 â†’ 3e-4
# =============================================================================