#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠç›‘ç£å­¦ä¹ æ•°æ®é›†
æ‰©å±•åŸæœ‰Datasetï¼Œæ”¯æŒis_labeledæ ‡è®°

ä¸åŸcsv_dataset.pyå…¼å®¹ï¼Œåªæ˜¯å¢åŠ äº†is_labeledå­—æ®µçš„å¤„ç†
"""
import pandas as pd
import numpy as np
import torch
from torch.utils.data import Dataset
from pathlib import Path
import soundfile as sf
import cv2


class SemiSupDataset(Dataset):
    """
    åŠç›‘ç£æ•°æ®é›†
    
    å…³é”®ç‰¹æ€§ï¼š
    - è¿”å›is_labeledå­—æ®µ
    - æ”¯æŒæ ‡æ³¨/æœªæ ‡æ³¨æ··åˆ
    - ä¸MixedBatchSampleré…åˆä½¿ç”¨
    
    CSVæ ¼å¼è¦æ±‚ï¼š
    - sample: æ ·æœ¬åç§°
    - audio: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    - video: è§†é¢‘æ–‡ä»¶è·¯å¾„
    - audio_start_s, audio_end_s: éŸ³é¢‘çª—å£
    - video_start_frame, video_end_frame: è§†é¢‘çª—å£
    - is_labeled: 0/1æ ‡è®°ï¼ˆå¿…éœ€ï¼‰
    - label: æ ‡ç­¾ï¼ˆå¯é€‰ï¼Œæœªæ ‡æ³¨æ ·æœ¬å¯ä»¥æ²¡æœ‰ï¼‰
    """
    def __init__(self,
                 windows_csv: str,
                 ann_csv: str = None,
                 classes: list = None,
                 audio_sr: int = 16000,
                 video_size: tuple = (224, 224),
                 num_frames: int = 16,
                 use_cache: bool = False):
        """
        Args:
            windows_csv: çª—å£CSVæ–‡ä»¶ï¼ˆéœ€åŒ…å«is_labeledåˆ—ï¼‰
            ann_csv: æ ‡æ³¨CSVæ–‡ä»¶ï¼ˆåŒ…å«labelåˆ—ï¼‰
            classes: ç±»åˆ«åˆ—è¡¨
            audio_sr: éŸ³é¢‘é‡‡æ ·ç‡
            video_size: è§†é¢‘å°ºå¯¸
            num_frames: è§†é¢‘å¸§æ•°
            use_cache: æ˜¯å¦ç¼“å­˜ç‰¹å¾
        """
        self.windows_csv = Path(windows_csv)
        self.ann_csv = Path(ann_csv) if ann_csv else None
        self.classes = classes or ['normal', 'defect']
        self.audio_sr = audio_sr
        self.video_size = video_size
        self.num_frames = num_frames
        self.use_cache = use_cache
        
        # åŠ è½½æ•°æ®
        self._load_data()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._print_stats()
    
    def _load_data(self):
        """åŠ è½½CSVæ•°æ®"""
        # 1. åŠ è½½windows
        self.df_windows = pd.read_csv(self.windows_csv)
        
        # æ£€æŸ¥å¿…éœ€åˆ—
        required_cols = ['sample', 'audio', 'video', 'is_labeled']
        missing = [c for c in required_cols if c not in self.df_windows.columns]
        
        if missing:
            raise ValueError(f"Windows CSVç¼ºå°‘å¿…éœ€åˆ—: {missing}")
        
        # 2. åŠ è½½æ ‡æ³¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if self.ann_csv and self.ann_csv.exists():
            df_ann = pd.read_csv(self.ann_csv)
            
            # åˆå¹¶æ ‡æ³¨
            if 'sample' in df_ann.columns and 'label' in df_ann.columns:
                # æŒ‰sampleåˆå¹¶
                self.df = self.df_windows.merge(
                    df_ann[['sample', 'label']],
                    on='sample',
                    how='left'
                )
            else:
                print("è­¦å‘Š: æ ‡æ³¨æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨åŸå§‹windows")
                self.df = self.df_windows.copy()
        else:
            self.df = self.df_windows.copy()
        
        # 3. å¤„ç†æ ‡ç­¾
        if 'label' not in self.df.columns:
            # å¦‚æœæ²¡æœ‰labelåˆ—ï¼Œåˆ›å»ºä¸€ä¸ªï¼ˆæœªæ ‡æ³¨æ ·æœ¬è®¾ä¸º-1ï¼‰
            self.df['label'] = -1
        
        # æœªæ ‡æ³¨æ ·æœ¬çš„labelè®¾ä¸º-1
        unlabeled_mask = self.df['is_labeled'] == 0
        self.df.loc[unlabeled_mask, 'label'] = -1
        
        # 4. åˆ›å»ºç±»åˆ«æ˜ å°„
        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}
        
        # è½¬æ¢å­—ç¬¦ä¸²æ ‡ç­¾ä¸ºç´¢å¼•
        if self.df['label'].dtype == 'object':
            self.df['label'] = self.df['label'].map(
                lambda x: self.class_to_idx.get(x, -1) if x != -1 else -1
            )
    
    def _print_stats(self):
        """æ‰“å°æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n{'='*70}")
        print(f"SemiSup Dataset Statistics")
        print(f"{'='*70}")
        print(f"Total samples: {len(self.df)}")
        
        # æ ‡æ³¨/æœªæ ‡æ³¨ç»Ÿè®¡
        n_labeled = (self.df['is_labeled'] == 1).sum()
        n_unlabeled = (self.df['is_labeled'] == 0).sum()
        
        print(f"  Labeled: {n_labeled} ({n_labeled/len(self.df)*100:.1f}%)")
        print(f"  Unlabeled: {n_unlabeled} ({n_unlabeled/len(self.df)*100:.1f}%)")
        
        # ç±»åˆ«åˆ†å¸ƒï¼ˆä»…æ ‡æ³¨æ ·æœ¬ï¼‰
        if n_labeled > 0:
            labeled_df = self.df[self.df['is_labeled'] == 1]
            print(f"\nClass distribution (labeled only):")
            for class_name, class_idx in self.class_to_idx.items():
                count = (labeled_df['label'] == class_idx).sum()
                print(f"  {class_name}: {count} ({count/n_labeled*100:.1f}%)")
        
        print(f"{'='*70}\n")
    
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        """
        è¿”å›ä¸€ä¸ªæ ·æœ¬
        
        Returns:
            dict:
                - video: [T, C, H, W] æˆ– [T, D]
                - audio: [T, freq] æˆ– [T, D]
                - label: int (æ ‡æ³¨æ ·æœ¬) æˆ– -1 (æœªæ ‡æ³¨æ ·æœ¬)
                - is_labeled: bool
                - index: int
        """
        row = self.df.iloc[idx]
        
        # 1. åŠ è½½éŸ³é¢‘
        audio = self._load_audio(row)
        
        # 2. åŠ è½½è§†é¢‘
        video = self._load_video(row)
        
        # 3. æ ‡ç­¾
        label = int(row['label'])
        is_labeled = bool(row['is_labeled'])
        
        return {
            'video': video,
            'audio': audio,
            'label': label,
            'is_labeled': is_labeled,
            'index': idx,
            'sample': row['sample']
        }
    
    def _load_audio(self, row):
        """åŠ è½½éŸ³é¢‘ç‰‡æ®µ"""
        audio_path = row['audio']
        t_start = row.get('audio_start_s', 0)
        t_end = row.get('audio_end_s', None)
        
        try:
            # è¯»å–éŸ³é¢‘
            y, sr = sf.read(audio_path)
            
            # å•å£°é“
            if y.ndim == 2:
                y = y.mean(axis=1)
            
            # é‡é‡‡æ ·
            if sr != self.audio_sr:
                from scipy import signal
                n_samples = int(len(y) * self.audio_sr / sr)
                y = signal.resample(y, n_samples)
                sr = self.audio_sr
            
            # æå–ç‰‡æ®µ
            if t_end is not None:
                start_idx = int(t_start * sr)
                end_idx = int(t_end * sr)
                y = y[start_idx:end_idx]
            
            # è½¬ä¸ºmelé¢‘è°±ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”ä½¿ç”¨VGGishï¼‰
            # è¿™é‡Œè¿”å›åŸå§‹éŸ³é¢‘ï¼Œåç»­åœ¨æ¨¡å‹ä¸­å¤„ç†
            audio_tensor = torch.from_numpy(y).float()
            
            # Paddingåˆ°å›ºå®šé•¿åº¦
            target_len = int(1.5 * sr)  # 1.5ç§’
            if len(audio_tensor) < target_len:
                audio_tensor = torch.nn.functional.pad(
                    audio_tensor, (0, target_len - len(audio_tensor))
                )
            else:
                audio_tensor = audio_tensor[:target_len]
            
            return audio_tensor.unsqueeze(0)  # [1, T]
            
        except Exception as e:
            print(f"è­¦å‘Š: éŸ³é¢‘åŠ è½½å¤±è´¥ {audio_path}: {e}")
            # è¿”å›é›¶å¼ é‡
            return torch.zeros(1, int(1.5 * self.audio_sr))
    
    def _load_video(self, row):
        """åŠ è½½è§†é¢‘å¸§"""
        video_path = row['video']
        f_start = int(row.get('video_start_frame', 0))
        f_end = int(row.get('video_end_frame', self.num_frames))
        
        try:
            cap = cv2.VideoCapture(str(video_path))
            
            frames = []
            frame_indices = np.linspace(f_start, f_end, self.num_frames, dtype=int)
            
            for fid in frame_indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, int(fid))
                ret, frame = cap.read()
                
                if not ret:
                    # ä½¿ç”¨æœ€åä¸€å¸§æˆ–é»‘å¸§
                    if frames:
                        frame = frames[-1].copy()
                    else:
                        frame = np.zeros((*self.video_size, 3), dtype=np.uint8)
                
                # è°ƒæ•´å°ºå¯¸
                frame = cv2.resize(frame, self.video_size)
                # BGR -> RGB
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                # å½’ä¸€åŒ–
                frame = frame.astype(np.float32) / 255.0
                
                frames.append(frame)
            
            cap.release()
            
            # [T, H, W, C] -> [T, C, H, W]
            video_tensor = torch.from_numpy(np.stack(frames)).permute(0, 3, 1, 2)
            
            return video_tensor
            
        except Exception as e:
            print(f"è­¦å‘Š: è§†é¢‘åŠ è½½å¤±è´¥ {video_path}: {e}")
            # è¿”å›é›¶å¼ é‡
            return torch.zeros(self.num_frames, 3, *self.video_size)
    
    def get_labeled_indices(self):
        """è¿”å›æ‰€æœ‰æ ‡æ³¨æ ·æœ¬çš„ç´¢å¼•"""
        return self.df[self.df['is_labeled'] == 1].index.tolist()
    
    def get_unlabeled_indices(self):
        """è¿”å›æ‰€æœ‰æœªæ ‡æ³¨æ ·æœ¬çš„ç´¢å¼•"""
        return self.df[self.df['is_labeled'] == 0].index.tolist()


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================
if __name__ == "__main__":
    print("="*70)
    print("SemiSup Dataset æµ‹è¯•")
    print("="*70)
    
    # åˆ›å»ºæ¨¡æ‹ŸCSV
    import tempfile
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
        f.write("sample,audio,video,audio_start_s,audio_end_s,video_start_frame,video_end_frame,is_labeled,label\n")
        
        for i in range(20):
            is_labeled = 1 if i < 5 else 0  # 25%æ ‡æ³¨
            label = i % 2 if is_labeled else -1
            
            f.write(f"sample_{i},audio_{i}.flac,video_{i}.avi,")
            f.write(f"0.0,1.5,0,48,{is_labeled},{label}\n")
        
        csv_path = f.name
    
    try:
        # åˆ›å»ºæ•°æ®é›†
        dataset = SemiSupDataset(
            windows_csv=csv_path,
            classes=['normal', 'defect']
        )
        
        # æµ‹è¯•ç´¢å¼•è·å–
        labeled_idx = dataset.get_labeled_indices()
        unlabeled_idx = dataset.get_unlabeled_indices()
        
        print(f"Labeled indices: {labeled_idx}")
        print(f"Unlabeled indices: {unlabeled_idx[:5]}...")
        
        # æµ‹è¯•æ•°æ®åŠ è½½ï¼ˆä¼šå¤±è´¥å› ä¸ºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½†å¯ä»¥çœ‹åˆ°æµç¨‹ï¼‰
        print(f"\nå°è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬...")
        try:
            sample = dataset[0]
            print(f"  âœ… æ ·æœ¬ç»“æ„æ­£ç¡®")
            print(f"     keys: {sample.keys()}")
        except Exception as e:
            print(f"  âš ï¸  åŠ è½½å¤±è´¥ï¼ˆé¢„æœŸï¼Œå› ä¸ºæ–‡ä»¶ä¸å­˜åœ¨ï¼‰: {e}")
        
        print(f"\nâœ… Datasetç»“æ„æµ‹è¯•é€šè¿‡!")
        
    finally:
        # æ¸…ç†
        import os
        os.remove(csv_path)
        # 2. å¦‚æœæä¾›äº†æ ‡æ³¨CSVï¼Œåˆå¹¶æ ‡ç­¾ä¿¡æ¯
        if self.ann_csv and self.ann_csv.exists():
            df_ann = pd.read_csv(self.ann_csv)
            # åˆå¹¶labelåˆ—
            if 'label' in df_ann.columns:
                self.df = self.df_windows.merge(
                    df_ann[['sample', 'label']],
                    on='sample',
                    how='left'
                )
            else:
                self.df = self.df_windows.copy()
        else:
            self.df = self.df_windows.copy()

        # 3. ç¡®ä¿is_labeledå­—æ®µä¸ºæ•´æ•°
        self.df['is_labeled'] = self.df['is_labeled'].astype(int)

        # 4. å¯¹äºæœªæ ‡æ³¨æ ·æœ¬ï¼Œè®¾ç½®labelä¸º-1ï¼ˆå ä½ç¬¦ï¼‰
        if 'label' not in self.df.columns:
            self.df['label'] = -1

        self.df.loc[self.df['is_labeled'] == 0, 'label'] = -1

        # 5. å¯¹äºå·²æ ‡æ³¨æ ·æœ¬ï¼Œå°†labelæ˜ å°„ä¸ºç±»åˆ«ç´¢å¼•
        if 'label' in self.df.columns:
            # å¦‚æœlabelå·²ç»æ˜¯å­—ç¬¦ä¸²ç±»åˆ«åï¼Œæ˜ å°„ä¸ºç´¢å¼•
            if self.df['label'].dtype == 'object':
                self.df['label'] = self.df['label'].apply(
                    lambda x: self.classes.index(x) if x in self.classes else -1
                )

        # 6. ç¼“å­˜ç›¸å…³
        self.cache = {} if use_cache else None


    def _print_stats(self):
        """æ‰“å°æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        total = len(self.df)
        labeled = (self.df['is_labeled'] == 1).sum()
        unlabeled = (self.df['is_labeled'] == 0).sum()

        print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {total}")
        print(f"  å·²æ ‡æ³¨: {labeled} ({100 * labeled / total:.1f}%)")
        print(f"  æœªæ ‡æ³¨: {unlabeled} ({100 * unlabeled / total:.1f}%)")

        if labeled > 0:
            label_dist = self.df[self.df['is_labeled'] == 1]['label'].value_counts()
            print(f"  æ ‡æ³¨åˆ†å¸ƒ:")
            for cls_idx, count in label_dist.items():
                cls_name = self.classes[cls_idx] if cls_idx < len(self.classes) else f"class_{cls_idx}"
                print(f"    {cls_name}: {count}")


    def __len__(self):
        return len(self.df)


    def __getitem__(self, idx):
        """
        è¿”å›æ ·æœ¬å­—å…¸

        Returns:
            dict: {
                'audio': tensor [audio_length]
                'video': tensor [num_frames, 3, H, W]
                'label': int (-1è¡¨ç¤ºæœªæ ‡æ³¨)
                'is_labeled': int (0æˆ–1)
                'sample_name': str
            }
        """
        # ä»ç¼“å­˜åŠ è½½
        if self.use_cache and idx in self.cache:
            return self.cache[idx]

        row = self.df.iloc[idx]

        # 1. åŠ è½½éŸ³é¢‘
        audio_path = row['audio']
        audio, sr = sf.read(audio_path)

        # éŸ³é¢‘çª—å£åˆ‡ç‰‡
        start_sample = int(row['audio_start_s'] * sr)
        end_sample = int(row['audio_end_s'] * sr)
        audio = audio[start_sample:end_sample]

        # é‡é‡‡æ ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if sr != self.audio_sr:
            from librosa import resample
            audio = resample(audio, orig_sr=sr, target_sr=self.audio_sr)

        audio_tensor = torch.from_numpy(audio).float()

        # 2. åŠ è½½è§†é¢‘
        video_path = row['video']
        cap = cv2.VideoCapture(str(video_path))

        start_frame = int(row['video_start_frame'])
        end_frame = int(row['video_end_frame'])
        total_frames = end_frame - start_frame

        # å‡åŒ€é‡‡æ ·num_frameså¸§
        frame_indices = np.linspace(start_frame, end_frame - 1, self.num_frames, dtype=int)

        frames = []
        for frame_idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()

            if ret:
                # BGR -> RGB
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                # Resize
                frame = cv2.resize(frame, self.video_size)
                # Normalize to [0, 1]
                frame = frame.astype(np.float32) / 255.0
                frames.append(frame)

        cap.release()

        # [T, H, W, C] -> [T, C, H, W]
        video_tensor = torch.from_numpy(np.array(frames)).permute(0, 3, 1, 2).float()

        # 3. ç»„è£…è¾“å‡º
        sample = {
            'audio': audio_tensor,
            'video': video_tensor,
            'label': int(row['label']),
            'is_labeled': int(row['is_labeled']),
            'sample_name': row['sample']
        }

        # ç¼“å­˜
        if self.use_cache:
            self.cache[idx] = sample

        return sample


    def get_labeled_indices(self):
        """è¿”å›æ‰€æœ‰å·²æ ‡æ³¨æ ·æœ¬çš„ç´¢å¼•"""
        return self.df[self.df['is_labeled'] == 1].index.tolist()


    def get_unlabeled_indices(self):
        """è¿”å›æ‰€æœ‰æœªæ ‡æ³¨æ ·æœ¬çš„ç´¢å¼•"""
        return self.df[self.df['is_labeled'] == 0].index.tolist()

# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================
if __name__ == "__main__":
    print("=" * 70)
    print("SemiSup Dataset æµ‹è¯•")
    print("=" * 70)

    # åˆ›å»ºæ¨¡æ‹ŸCSV
    import tempfile

    with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
        f.write("sample,audio,video,audio_start_s,audio_end_s,video_start_frame,video_end_frame,is_labeled,label\n")

        for i in range(20):
            is_labeled = 1 if i < 5 else 0  # 25%æ ‡æ³¨
            label = i % 2 if is_labeled else -1

            f.write(f"sample_{i},audio_{i}.flac,video_{i}.avi,")
            f.write(f"0.0,1.5,0,48,{is_labeled},{label}\n")

        csv_path = f.name

    try:
        # åˆ›å»ºæ•°æ®é›†
        dataset = SemiSupDataset(
            windows_csv=csv_path,
            classes=['normal', 'defect']
        )

        # æµ‹è¯•ç´¢å¼•è·å–
        labeled_idx = dataset.get_labeled_indices()
        unlabeled_idx = dataset.get_unlabeled_indices()

        print(f"\nğŸ“‹ ç´¢å¼•ä¿¡æ¯:")
        print(f"  Labeled indices: {labeled_idx}")
        print(f"  Unlabeled indices: {unlabeled_idx[:5]}...")

        # æµ‹è¯•æ•°æ®åŠ è½½ï¼ˆä¼šå¤±è´¥å› ä¸ºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½†å¯ä»¥çœ‹åˆ°æµç¨‹ï¼‰
        print(f"\nğŸ” å°è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬...")
        try:
            sample = dataset[0]
            print(f"  âœ… æ ·æœ¬ç»“æ„æ­£ç¡®")
            print(f"     keys: {sample.keys()}")
        except Exception as e:
            print(f"  âš ï¸  åŠ è½½å¤±è´¥ï¼ˆé¢„æœŸï¼Œå› ä¸ºæ–‡ä»¶ä¸å­˜åœ¨ï¼‰: {str(e)[:50]}")

        print(f"\nâœ… Datasetç»“æ„æµ‹è¯•é€šè¿‡!")

    finally:
        # æ¸…ç†
        import os

        os.remove(csv_path)